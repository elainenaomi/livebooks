<!-- livebook:{"app_settings":{"show_source":true,"slug":"elixir-ai"},"file_entries":[{"name":"SCR-20240803-jcvm.jpeg","type":"attachment"}]} -->

# Elixir, Concurrency and AI

```elixir
Mix.install(
  [
    {:req, "~> 0.5.4"},
    {:bandit, "~> 1.5"},
    {:kino, "~> 0.13.2"},
    {:kino_vega_lite, "~> 0.1.13"},
    {:kino_db, "~> 0.2.8"},
    {:exqlite, "~> 0.23.0"},
    {:nx, "~> 0.7.3"},
    {:kino_bumblebee, "~> 0.5.0"},
    {:exla, ">= 0.0.0"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## Welcome

Shamelessly copied from:

https://www.youtube.com/watch?v=pas9WdWIBHs&ab_channel=GOTOConferences

And from:

https://github.com/georgeguimaraes/livebooks/blob/main/2024-07-26-elixir-ai.livemd

## Concurrency

Elixir supports pattern-matching, polymorphism via protocols, meta-programming, and more. But today, we will focus on its concurrency features. In the Erlang VM, all code runs inside lightweight threads called processes. We can literally create millions of them:

```elixir
for _ <- 1..1_000_000 do
  spawn(fn -> :ok end)
end
```

Process communicate by sending messages between them:

```elixir
parent = self()

child =
  spawn(fn ->
    receive do
      :ping -> send(parent, :pong)
    end
  end)

send(child, :ping)

receive do
  :pong -> :it_worked!
end
```

And Livebook can helps us see how processes communicate between them:

```elixir
Kino.Process.render_seq_trace(fn ->
  parent = self()

  child =
    spawn(fn ->
      receive do
        :ping -> send(parent, :pong)
      end
    end)

  send(child, :ping)

  receive do
    :pong -> :it_worked!
  end
end)
```

Maybe you want to see how Elixir can perform multiple tasks at once, scaling on both CPU and IO?

```elixir
Kino.Process.render_seq_trace(fn ->
  ["/foo", "/bar", "/baz", "/bat"]
  |> Task.async_stream(
    fn _ -> Process.sleep(Enum.random(100..300)) end,
    max_concurrency: 4
  )
  |> Enum.to_list()
end)
```

Let's take visualizations even further!

## Plotting live data

The Erlang VM provides a great set of tools for observability. Let's gather information about all processes:

```elixir
processes =
  for pid <- Process.list() do
    info = Process.info(pid, [:reductions, :memory, :status])

    %{
      pid: inspect(pid),
      reductions: info[:reductions],
      memory: info[:memory],
      status: info[:status]
    }
  end
```

But how to plot it?

### Smart cell here!

<!-- livebook:{"attrs":"eyJjaGFydF90aXRsZSI6bnVsbCwiaGVpZ2h0Ijo1MDAsImxheWVycyI6W3siYWN0aXZlIjp0cnVlLCJjaGFydF90eXBlIjoicG9pbnQiLCJjb2xvcl9maWVsZCI6InN0YXR1cyIsImNvbG9yX2ZpZWxkX2FnZ3JlZ2F0ZSI6bnVsbCwiY29sb3JfZmllbGRfYmluIjpudWxsLCJjb2xvcl9maWVsZF9zY2FsZV9zY2hlbWUiOm51bGwsImNvbG9yX2ZpZWxkX3R5cGUiOiJub21pbmFsIiwiZGF0YV92YXJpYWJsZSI6InByb2Nlc3NlcyIsImdlb2RhdGFfY29sb3IiOiJibHVlIiwibGF0aXR1ZGVfZmllbGQiOm51bGwsImxvbmdpdHVkZV9maWVsZCI6bnVsbCwieF9maWVsZCI6Im1lbW9yeSIsInhfZmllbGRfYWdncmVnYXRlIjpudWxsLCJ4X2ZpZWxkX2JpbiI6bnVsbCwieF9maWVsZF9zY2FsZV90eXBlIjoibG9nIiwieF9maWVsZF90eXBlIjoicXVhbnRpdGF0aXZlIiwieV9maWVsZCI6InJlZHVjdGlvbnMiLCJ5X2ZpZWxkX2FnZ3JlZ2F0ZSI6bnVsbCwieV9maWVsZF9iaW4iOm51bGwsInlfZmllbGRfc2NhbGVfdHlwZSI6ImxvZyIsInlfZmllbGRfdHlwZSI6InF1YW50aXRhdGl2ZSJ9XSwidmxfYWxpYXMiOiJFbGl4aXIuVmVnYUxpdGUiLCJ3aWR0aCI6NTAwfQ","chunks":null,"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 500, height: 500)
|> VegaLite.data_from_values(processes, only: ["memory", "reductions", "status"])
|> VegaLite.mark(:point)
|> VegaLite.encode_field(:x, "memory", type: :quantitative, scale: [type: :log])
|> VegaLite.encode_field(:y, "reductions", type: :quantitative, scale: [type: :log])
|> VegaLite.encode_field(:color, "status", type: :nominal)
```

## Web + AI

```elixir
defmodule Web do
  use Plug.Builder

  plug :fetch_query_params
  plug :render

  def render(conn, _opts) do
    name = conn.params["name"]
    Plug.Conn.send_resp(conn, 200, "Hello world, #{name}!")
  end
end
```

```elixir
Kino.start_child!({Bandit, plug: Web, port: 9010})
```

```elixir
Req.get!("http://localhost:9010", params: [name: "Elixir Guild"])
```

## Neural Network Smart Cell

<!-- livebook:{"attrs":"eyJjb21waWxlciI6ImV4bGEiLCJtYXhfbmV3X3Rva2VucyI6MTAwLCJ0YXNrX2lkIjoic3BlZWNoX3RvX3RleHQiLCJ2YXJpYW50X2lkIjoid2hpc3Blcl90aW55In0","chunks":[[0,654],[656,1063]],"kind":"Elixir.KinoBumblebee.TaskCell","livebook_object":"smart_cell"} -->

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "openai/whisper-tiny"})
{:ok, featurizer} = Bumblebee.load_featurizer({:hf, "openai/whisper-tiny"})
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "openai/whisper-tiny"})
{:ok, generation_config} = Bumblebee.load_generation_config({:hf, "openai/whisper-tiny"})
generation_config = Bumblebee.configure(generation_config, max_new_tokens: 100)

serving =
  Bumblebee.Audio.speech_to_text_whisper(
    model_info,
    featurizer,
    tokenizer,
    generation_config,
    compile: [batch_size: 4],
    chunk_num_seconds: 30,
    timestamps: :segments,
    stream: true,
    defn_options: [compiler: EXLA]
  )

audio_input = Kino.Input.audio("Audio", sampling_rate: featurizer.sampling_rate)
form = Kino.Control.form([audio: audio_input], submit: "Run")
frame = Kino.Frame.new()

Kino.listen(form, fn %{data: %{audio: audio}} ->
  if audio do
    audio =
      audio.file_ref
      |> Kino.Input.file_path()
      |> File.read!()
      |> Nx.from_binary(:f32)
      |> Nx.reshape({:auto, audio.num_channels})
      |> Nx.mean(axes: [1])

    Kino.Frame.render(frame, Kino.Text.new("(Start of transcription)", chunk: true))

    for chunk <- Nx.Serving.run(serving, audio) do
      [start_mark, end_mark] =
        for seconds <- [chunk.start_timestamp_seconds, chunk.end_timestamp_seconds] do
          seconds |> round() |> Time.from_seconds_after_midnight() |> Time.to_string()
        end

      text = "
#{start_mark}-#{end_mark}: #{chunk.text}"
      Kino.Frame.append(frame, Kino.Text.new(text, chunk: true))
    end

    Kino.Frame.append(frame, Kino.Text.new("\n(End of transcription)", chunk: true))
  end
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```

<!-- livebook:{"attrs":"eyJjb21waWxlciI6ImV4bGEiLCJzZXF1ZW5jZV9sZW5ndGgiOjEwMCwidGFza19pZCI6InRleHRfY2xhc3NpZmljYXRpb24iLCJ0b3BfayI6bnVsbCwidmFyaWFudF9pZCI6InJvYmVydGFfYmVydHdlZXRfZW1vdGlvbiJ9","chunks":[[0,335],[337,507]],"kind":"Elixir.KinoBumblebee.TaskCell","livebook_object":"smart_cell"} -->

```elixir
{:ok, model_info} =
  Bumblebee.load_model({:hf, "finiteautomata/bertweet-base-emotion-analysis"})

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "vinai/bertweet-base"})

serving =
  Bumblebee.Text.text_classification(model_info, tokenizer,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )

text_input = Kino.Input.textarea("Text", default: "Oh wow, I didn't know that!")
form = Kino.Control.form([text: text_input], submit: "Run")
frame = Kino.Frame.new()

Kino.listen(form, fn %{data: %{text: text}} ->
  Kino.Frame.render(frame, Kino.Text.new("Running..."))
  output = Nx.Serving.run(serving, text)

  output.predictions
  |> Enum.map(&{&1.label, &1.score})
  |> Kino.Bumblebee.ScoredList.new()
  |> then(&Kino.Frame.render(frame, &1))
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```

## Nx.Serving + Batched run

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "finiteautomata/bertweet-base-emotion-analysis"})
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "vinai/bertweet-base"})

serving = 
  Bumblebee.Text.text_classification(model_info, tokenizer, 
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )

Kino.start_child!({Nx.Serving, serving: serving, name: :my_web_ai})
```

```elixir


text_input = Kino.Input.textarea("Text", default: "Oh wow, I didn't know that!")
form = Kino.Control.form([text: text_input], submit: "Run")
frame = Kino.Frame.new()

Kino.listen(form, fn %{data: %{text: text}} ->
  Kino.Frame.render(frame, Kino.Text.new("Running..."))
  output = Nx.Serving.batched_run(:my_web_ai, text)

  output.predictions
  |> Enum.map(&{&1.label, &1.score})
  |> Kino.Bumblebee.ScoredList.new()
  |> then(&Kino.Frame.render(frame, &1))
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```

## A New Web App with AI

```elixir
defmodule WebAI do
  use Plug.Builder

  plug :fetch_query_params
  plug :render

  def render(conn, _opts) do
    text = conn.params["text"]
    output = Nx.Serving.batched_run(:my_web_ai, text)

    [ %{ label: label, score: _ } | _ ] = output.predictions 
    
    Plug.Conn.send_resp(conn, 200, "this was #{label}!")
  end
end

Kino.start_child!({Bandit, plug: WebAI, port: 9003})
```

```elixir
Req.get!("http://localhost:9003", params: [text: "elixir is awesome"])
```

<!-- livebook:{"offset":8763,"stamp":{"token":"XCP.5mPRN3bZTsKd4mwWRLnmxm0G7af5vXv3YZAZneTjU70dantT0M1lWoWugAxwjsCJmGu7s5UzHGKyFgDiP8_B8t8LSdp1jEefiha3C_jiRkNMm2vul67qlde-","version":2}} -->
